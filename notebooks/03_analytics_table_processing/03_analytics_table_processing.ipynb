{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ax3alogiklskgt2k3w4v",
   "authorId": "6690310009356",
   "authorName": "YOHANMARKOSE",
   "authorEmail": "markose.y@northeastern.edu",
   "sessionId": "a112945e-9c5f-45c2-905d-7f6c58b8483c",
   "lastEditTime": 1740632539053
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "b4d81575-5a56-4315-8949-3451cf57c500",
   "metadata": {
    "language": "sql",
    "name": "sql_get_context",
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT current_database() AS DATABASE_NAME, current_schema() AS SCHEMA_NAME",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "edd2bd6e-22f7-413c-bb64-52288c4598d3",
   "metadata": {
    "language": "python",
    "name": "imports",
    "collapsed": false
   },
   "outputs": [],
   "source": "# Import python packages\nimport logging\n# from snowflake.core import Root\nfrom snowflake.snowpark.context import get_active_session\n\nlogger = logging.getLogger(\"fred_logger\")\n\ncurrent_context_df = cells.sql_get_context.to_pandas()\ndatabase_name = current_context_df.iloc[0,0]\nschema_name = current_context_df.iloc[0,1]\n\nsession = get_active_session()\n\nlogger.info(\"03_analytics_table_processing start\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "sproc_incremental_updates"
   },
   "source": "CREATE OR REPLACE PROCEDURE merge_fred_updates_sp(DATABASE_NAME STRING, SCHEMA_NAME STRING, ENV STRING)\n RETURNS STRING\n LANGUAGE PYTHON\n RUNTIME_VERSION=3.10\n PACKAGES=('snowflake-snowpark-python')\n HANDLER='main'\nAS\n$$\nfrom snowflake.snowpark import Session\nimport snowflake.snowpark.functions as F\n\n\n\ndef table_exists(session, schema='', name=''):\n    exists = session.sql(\"SELECT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{}' AND TABLE_NAME = '{}') AS TABLE_EXISTS\".format(schema, name)).collect()[0]['TABLE_EXISTS']\n    return exists\n\ndef create_fred_table(session, DATABASE_NAME, ENV):\n    _ = session.sql(f\"CREATE TABLE FRED_10Y_2Y LIKE {DATABASE_NAME}.{ENV}_HARMONIZED.FRED_FLATTENED\").collect()\n    _ = session.sql(\"ALTER TABLE FRED_10Y_2Y ADD COLUMN META_UPDATED_AT TIMESTAMP\").collect()\n\n# Uncomment only if we need to process another table\n# def create_fred_stream(session):\n#     _ = session.sql(\"CREATE STREAM FRED_10Y_2Y_STREAM ON TABLE FRED_10Y_2Y\").collect()\n\ndef merge_fred_updates(session, DATABASE_NAME, ENV, SCHEMA_NAME):\n    # _ = session.sql('ALTER WAREHOUSE HOL_WH SET WAREHOUSE_SIZE = XLARGE WAIT_FOR_COMPLETION = TRUE').collect()\n\n    source = session.table(f\"{DATABASE_NAME}.{ENV}_HARMONIZED.FRED_STREAM\")\n    target = session.table(f\"{DATABASE_NAME}.{SCHEMA_NAME}.FRED_10Y_2Y\")\n\n    # TODO: Is the if clause supposed to be based on \"META_UPDATED_AT\"?\n    cols_to_update = {c: source[c] for c in source.schema.names if \"METADATA\" not in c}\n    metadata_col_to_update = {\"META_UPDATED_AT\": F.current_timestamp()}\n    updates = {**cols_to_update, **metadata_col_to_update}\n\n    # merge into DIM_CUSTOMER\n    target.merge(source, target['OBSERVATION_DATE'] == source['OBSERVATION_DATE'], \\\n                        [F.when_matched().update(updates), F.when_not_matched().insert(updates)])\n    \ndef main(session: Session, DATABASE_NAME: str, SCHEMA_NAME: str, ENV: str) -> str:\n    \n    if not table_exists(session, schema=SCHEMA_NAME, name='FRED_10Y_2Y'):\n            create_fred_table(session, DATABASE_NAME, ENV)\n            # create_fred_stream(session)\n    # Process data incrementally\n    merge_fred_updates(session, DATABASE_NAME, ENV, SCHEMA_NAME)\n    return \"FRED_10Y_2Y table updated successfully!\"\n\n$$;\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "# To call the sproc\n# session.use_schema(f\"{database_name}.{schema_name}\")\n# env = schema_name[:3]\n# session.sql(f\"CALL merge_fred_updates_sp('{database_name}', '{schema_name}', '{env}')\").collect()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "699d836d-4b8b-4632-a055-15aa2286a36a",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "collapsed": false
   },
   "outputs": [],
   "source": "def create_spread_udf(session, schema_name):\n    session.sql(f\"\"\"\n        CREATE OR REPLACE FUNCTION {schema_name}.calculate_spread(ten_year_yield FLOAT, two_year_yield FLOAT) \n        RETURNS FLOAT \n        LANGUAGE PYTHON \n        RUNTIME_VERSION = '3.8' \n        PACKAGES = ('snowflake-snowpark-python')\n        HANDLER = 'calculate_spread' \n        AS \n        $$\ndef calculate_spread(ten_year_yield, two_year_yield):\n    if ten_year_yield is None or two_year_yield is None:\n        return None\n    return ten_year_yield - two_year_yield\n        $$;\n        \"\"\").collect()\n\ncreate_spread_udf(session, schema_name)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c262443e-6c67-4385-bab0-e7a76d9d4f19",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE FUNCTION CHECK_SPREAD_STATUS(spread FLOAT)\nRETURNS STRING\nAS\n$$\n    CASE\n        WHEN spread > 0 THEN 'POSITIVE'\n        WHEN spread < 0 THEN 'NEGATIVE'\n        ELSE 'ZERO'\n    END\n$$;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ae14228-61bb-4f8e-bb9f-7367e59bbf45",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE PROCEDURE create_analytical_tables_sp(SCHEMA_NAME STRING, TABLE_NAME STRING)\n RETURNS STRING\n LANGUAGE PYTHON\n RUNTIME_VERSION=3.10\n PACKAGES=('snowflake-snowpark-python')\n HANDLER='main'\nAS\n$$\nimport time\nfrom snowflake.snowpark import Session\nimport snowflake.snowpark.types as T\nimport snowflake.snowpark.functions as F\n\n\ndef table_exists(session, schema='', name=''):\n    exists = session.sql(\"SELECT EXISTS (SELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = '{}' AND TABLE_NAME = '{}') AS TABLE_EXISTS\".format(schema, name)).collect()[0]['TABLE_EXISTS']\n    return exists\n\n\ndef create_fred_combined_weekly_table(session, source_schema, source_table):\n    \"\"\"Create the weekly aggregation table if it doesn't exist\"\"\"\n    COMBINED_COLUMNS = [\n        T.StructField(\"WEEK_START\", T.DateType()),\n        T.StructField(\"TOTAL_RECORDS\", T.DecimalType()),\n        T.StructField(\"MIN_10Y\", T.DecimalType()),\n        T.StructField(\"MAX_10Y\", T.DecimalType()),\n        T.StructField(\"AVG_10Y\", T.DecimalType()),\n        T.StructField(\"MIN_2Y\", T.DecimalType()),\n        T.StructField(\"MAX_2Y\", T.DecimalType()),\n        T.StructField(\"AVG_2Y\", T.DecimalType()),\n        T.StructField(\"AVG_SPREAD\", T.DecimalType()),\n        T.StructField(\"SPREAD_STATUS\", T.StringType()),\n        T.StructField(\"META_UPDATED_AT\", T.TimestampType())\n    ]\n    COMBINED_SCHEMA = T.StructType(COMBINED_COLUMNS)\n\n    session.create_dataframe([[None]*len(COMBINED_SCHEMA.names)], schema=COMBINED_SCHEMA) \\\n           .na.drop() \\\n           .write.mode('overwrite').save_as_table(f'{source_schema}.FRED_COMBINED_WEEKLY')\n    print(\"FRED_COMBINED_WEEKLY table created\")\n\n\ndef create_fred_combined_monthly_table(session, source_schema, source_table):\n    \"\"\"Create the monthly aggregation table if it doesn't exist\"\"\"\n    COMBINED_COLUMNS = [\n        T.StructField(\"MONTH_START\", T.DateType()),\n        T.StructField(\"TOTAL_RECORDS\", T.DecimalType()),\n        T.StructField(\"MIN_10Y\", T.DecimalType()),\n        T.StructField(\"MAX_10Y\", T.DecimalType()),\n        T.StructField(\"AVG_10Y\", T.DecimalType()),\n        T.StructField(\"MIN_2Y\", T.DecimalType()),\n        T.StructField(\"MAX_2Y\", T.DecimalType()),\n        T.StructField(\"AVG_2Y\", T.DecimalType()),\n        T.StructField(\"AVG_SPREAD\", T.DecimalType()),\n        T.StructField(\"SPREAD_STATUS\", T.StringType()),\n        T.StructField(\"META_UPDATED_AT\", T.TimestampType())\n    ]\n    COMBINED_SCHEMA = T.StructType(COMBINED_COLUMNS)\n\n    session.create_dataframe([[None]*len(COMBINED_SCHEMA.names)], schema=COMBINED_SCHEMA) \\\n           .na.drop() \\\n           .write.mode('overwrite').save_as_table(f'{source_schema}.FRED_COMBINED_MONTHLY')\n    print(\"FRED_COMBINED_MONTHLY table created\")\n\n\ndef aggregate_fred_daily(session, source_schema, source_table):\n    \"\"\"Aggregate data at daily level and calculate spreads\"\"\"\n    # Reference the combined source table\n    source_table_ref = f\"{source_schema}.{source_table}\"\n    fred_combined = session.table(source_table_ref)\n    \n    # Calculate spread (10Y - 2Y)\n    fred_daily = fred_combined.select(\n        fred_combined['OBSERVATION_DATE'].alias('OBS_DATE'),\n        fred_combined['10Y_YIELD'],\n        fred_combined['2Y_YIELD'],\n        F.call_function(\"calculate_spread\", fred_combined['10Y_YIELD'], fred_combined['2Y_YIELD']).alias('SPREAD'),\n        F.call_function(\"check_spread_status\", F.call_function(\"calculate_spread\", F.col('10Y_YIELD'), F.col('2Y_YIELD'))).alias(\"SPREAD_STATUS\")\n    )\n    \n    fred_daily.write.mode('overwrite').save_as_table(f'{source_schema}.FRED_COMBINED_DAILY')\n    print(\"FRED_DAILY table aggregated\")\n\n\ndef aggregate_fred_weekly(session, source_schema, source_table):\n    \"\"\"Aggregate data at weekly level from the source table\"\"\"\n    # Reference the combined source table\n    source_table_ref = f\"{source_schema}.{source_table}\"\n    fred_combined = session.table(source_table_ref)\n    \n    # Perform weekly aggregation\n    fred_weekly_agg = fred_combined.group_by(F.date_trunc('WEEK', F.col('OBSERVATION_DATE')).alias(\"WEEK_START\")) \\\n                                   .agg(\n                                       F.count('OBSERVATION_DATE').alias(\"TOTAL_RECORDS\"),\n                                       F.round(F.min('10Y_YIELD'), 2).alias(\"MIN_10Y\"),\n                                       F.round(F.max('10Y_YIELD'), 2).alias(\"MAX_10Y\"),\n                                       F.round(F.avg('10Y_YIELD'), 2).alias(\"AVG_10Y\"),\n                                       F.round(F.min('2Y_YIELD'), 2).alias(\"MIN_2Y\"),\n                                       F.round(F.max('2Y_YIELD'), 2).alias(\"MAX_2Y\"),\n                                       F.round(F.avg('2Y_YIELD'), 2).alias(\"AVG_2Y\"),\n                                       F.round(F.avg(F.call_function(f\"{source_schema}.calculate_spread\", \n                                                                  F.col('10Y_YIELD'), F.col('2Y_YIELD'))), 2).alias(\"AVG_SPREAD\"),\n                                       F.call_function(\"CHECK_SPREAD_STATUS\", F.avg(F.call_function(\"calculate_spread\", F.col('10Y_YIELD'), F.col('2Y_YIELD')))).alias(\"SPREAD_STATUS\")\n                                   )\n    \n    # Add timestamp and write to table\n    fred_weekly_agg = fred_weekly_agg.withColumn(\"META_UPDATED_AT\", F.current_timestamp())\n    fred_weekly_agg.write.mode('overwrite').save_as_table(f'{source_schema}.FRED_COMBINED_WEEKLY')\n    \n    print(\"FRED_COMBINED_WEEKLY table aggregated\")\n\n\ndef aggregate_fred_monthly(session, source_schema, source_table):\n    \"\"\"Aggregate data at monthly level from the source table\"\"\"\n    # Reference the combined source table\n    source_table_ref = f\"{source_schema}.{source_table}\"\n    fred_combined = session.table(source_table_ref)\n    \n    # Perform monthly aggregation\n    fred_monthly_agg = fred_combined.group_by(F.date_trunc('MONTH', F.col('OBSERVATION_DATE')).alias(\"MONTH_START\")) \\\n                                    .agg(\n                                        F.count('OBSERVATION_DATE').alias(\"TOTAL_RECORDS\"),\n                                        F.round(F.min('10Y_YIELD'), 2).alias(\"MIN_10Y\"),\n                                        F.round(F.max('10Y_YIELD'), 2).alias(\"MAX_10Y\"),\n                                        F.round(F.avg('10Y_YIELD'), 2).alias(\"AVG_10Y\"),\n                                        F.round(F.min('2Y_YIELD'), 2).alias(\"MIN_2Y\"),\n                                        F.round(F.max('2Y_YIELD'), 2).alias(\"MAX_2Y\"),\n                                        F.round(F.avg('2Y_YIELD'), 2).alias(\"AVG_2Y\"),\n                                        F.round(F.avg(F.call_function(f\"{source_schema}.calculate_spread\", \n                                                                  F.col('10Y_YIELD'), F.col('2Y_YIELD'))), 2).alias(\"AVG_SPREAD\"),\n                                        F.call_function(\"CHECK_SPREAD_STATUS\", F.avg(F.call_function(\"calculate_spread\", F.col('10Y_YIELD'), F.col('2Y_YIELD')))).alias(\"SPREAD_STATUS\")\n                                    )\n    \n    # Add timestamp and write to table\n    fred_monthly_agg = fred_monthly_agg.withColumn(\"META_UPDATED_AT\", F.current_timestamp())\n    fred_monthly_agg.write.mode('overwrite').save_as_table(f'{source_schema}.FRED_COMBINED_MONTHLY')\n    \n    print(\"FRED_COMBINED_MONTHLY table aggregated\")\n\ndef main(session: Session, SCHEMA_NAME, TABLE_NAME) -> str:\n    if not table_exists(session, schema=SCHEMA_NAME, name=TABLE_NAME):\n        return f\"Error: Source table {SCHEMA_NAME}.{TABLE_NAME} does not exist\"\n    \n    print(f\"Source table {SCHEMA_NAME}.{TABLE_NAME} found\")\n    \n    # Create aggregate tables if they don't exist\n    if not table_exists(session, schema=SCHEMA_NAME, name='FRED_COMBINED_WEEKLY'):\n        create_fred_combined_weekly_table(session, SCHEMA_NAME, TABLE_NAME)\n    \n    if not table_exists(session, schema=SCHEMA_NAME, name='FRED_COMBINED_MONTHLY'):\n        create_fred_combined_monthly_table(session, SCHEMA_NAME, TABLE_NAME)\n    \n    # Run aggregations\n    aggregate_fred_daily(session, SCHEMA_NAME, TABLE_NAME)\n    aggregate_fred_weekly(session, SCHEMA_NAME, TABLE_NAME)\n    aggregate_fred_monthly(session, SCHEMA_NAME, TABLE_NAME)\n\n    return f\"Successfully aggregated analytics tables from {SCHEMA_NAME}.{TABLE_NAME}\"\n$$;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6bad5c8b-fe7e-45f4-91c0-cc8fac31bbc7",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# To call the sproc\n# session.sql(f\"CALL create_analytical_tables_sp('{schema_name}', 'FRED_10Y_2Y')\").collect()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce1876d7-eb2b-4d20-9807-8f50ae95fff9",
   "metadata": {
    "language": "sql",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- drop table FRED_COMBINED_MONTHLY;\n-- drop table FRED_COMBINED_WEEKLY;\n-- drop table FRED_DAILY;\n-- drop table FRED_MONTHLY;\n-- drop table FRED_WEEKLY;",
   "execution_count": null
  }
 ]
}